{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of nb-01.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathyouf/Kaggle_Helpers/blob/master/chatbot_MLT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CdfBZE3tky2",
        "colab_type": "text"
      },
      "source": [
        "Dialogue systems use a variety of mechanisms to carryout informative and coherent conversations withtheir users.   These conversations can be achieved through rule-basd,  template-based, retrieval-based approaches or in a data-driven manner that teaches the agent to learn from raw conversational data. This workshop will focus on the retreival-based method. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "129zo3dltky2",
        "colab_type": "text"
      },
      "source": [
        "## Retreival-Based Chatbot\n",
        "A retrieval-based agent or chatbot retrieves related responses from queries in the corpus that are similar to the given query.  We are not interested in generating a new response, but select the most suitable response (originally made to other queries) as reply to the current query. We will be try to do this by having a set of questions with labelled intents and then try to classify the intent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FHQVD_Atky3",
        "colab_type": "text"
      },
      "source": [
        "### Accessing Colab\n",
        "\n",
        "- Sign in to you Google account.\n",
        "- Access the [Colab Welcome Page](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true) and click on ‘Github’. In the ‘Enter a GitHub URL or search by organization or user’ line enter `https://github.com/bespoke-inc/bespoke-public-talks`. We will be using the notebook in folder `2020/2020-08-22-MLT-Rules-to-DL`\n",
        "- You need to tell Colab that you are interested in using a GPU. You can do this by clicking on the `Runtime` tab and selecting `Change runtime type`. A pop-up window will appear. Select `GPU` from the menu and `Save`.\n",
        "- Save your work to Google Drive by clicking on ‘File’ and then ‘Save’ and then `SAVE A COPY IN DRIVE.` in the pop-up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I9r3M_Stky4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97ead9b1-776d-4ea5-f315-77c035fde961"
      },
      "source": [
        "#install the necessary dependencies by uncommenting and running the following commands:\n",
        "!wget https://raw.githubusercontent.com/bespoke-inc/bespoke-public-talks/master/2020/2020-08-22-MLT-Rules-to-DL/requirements.txt\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-22 05:52:13--  https://raw.githubusercontent.com/bespoke-inc/bespoke-public-talks/master/2020/2020-08-22-MLT-Rules-to-DL/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 114 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "\rrequirements.txt      0%[                    ]       0  --.-KB/s               \rrequirements.txt    100%[===================>]     114  --.-KB/s    in 0s      \n",
            "\n",
            "2020-08-22 05:52:13 (6.85 MB/s) - ‘requirements.txt’ saved [114/114]\n",
            "\n",
            "Collecting nltk==3.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/56/90178929712ce427ebad179f8dc46c8deef4e89d4c853092bee1efd57d05/nltk-3.4.1.zip (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 2.8MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/27/e35e7c6e6a52fab9fcc64fc2b20c6b516eba930bb02b10ace3b38200d3ab/numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.3MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.20.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/82/c0de5839d613b82bddd088599ac0bbfbbbcbd8ca470680658352d2c435bd/scikit_learn-0.20.3-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4MB 40.1MB/s \n",
            "\u001b[?25hCollecting spacy==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/c7/e66e2af1cfa418c3a3917c116c4e00ccffa546f18f59e6acd7953d833c5c/spacy-2.3.0-cp36-cp36m-manylinux1_x86_64.whl (10.0MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0MB 172kB/s \n",
            "\u001b[?25hRequirement already satisfied: fastai==1.0.61 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.0.61)\n",
            "Collecting transformers==2.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 37.8MB/s \n",
            "\u001b[?25hCollecting fuzzywuzzy==0.17.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.4.1->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.3->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0->-r requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0->-r requirements.txt (line 4)) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0->-r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0->-r requirements.txt (line 4)) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0->-r requirements.txt (line 4)) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0->-r requirements.txt (line 4)) (49.2.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0->-r requirements.txt (line 4)) (3.0.2)\n",
            "Collecting thinc==7.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/ae/ef3ae5e93639c0ef8e3eb32e3c18341e511b3c515fcfc603f4b808087651/thinc-7.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 36.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0->-r requirements.txt (line 4)) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0->-r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0->-r requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0->-r requirements.txt (line 4)) (1.1.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61->-r requirements.txt (line 5)) (2.7.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61->-r requirements.txt (line 5)) (7.0.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61->-r requirements.txt (line 5)) (0.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61->-r requirements.txt (line 5)) (3.13)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61->-r requirements.txt (line 5)) (7.352.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61->-r requirements.txt (line 5)) (20.4)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61->-r requirements.txt (line 5)) (1.6.0+cu101)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61->-r requirements.txt (line 5)) (4.6.3)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61->-r requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61->-r requirements.txt (line 5)) (0.7.0+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61->-r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61->-r requirements.txt (line 5)) (1.0.5)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.61->-r requirements.txt (line 5)) (0.2.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r requirements.txt (line 6)) (3.0.12)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r requirements.txt (line 6)) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 38.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.0->-r requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.0->-r requirements.txt (line 4)) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.0->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.0->-r requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.0->-r requirements.txt (line 4)) (1.7.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai==1.0.61->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai==1.0.61->-r requirements.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.61->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.61->-r requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.61->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==1.0.61->-r requirements.txt (line 5)) (2018.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0->-r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0->-r requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.3.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Building wheels for collected packages: nltk, sacremoses\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.1-cp36-none-any.whl size=1445925 sha256=085315c24b494446dccde126cad1170e5c6f2de847b1e143fb3aa173c2235f71\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/8a/10/d646015f33c525688e91986c4544c68019b19a473cb33d3b55\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=977c9a14bf2266926173c64be8d691a726dfda6dd798c9556560e51c711ef76b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built nltk sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: nltk, numpy, scikit-learn, thinc, spacy, tokenizers, sentencepiece, sacremoses, transformers, fuzzywuzzy\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed fuzzywuzzy-0.17.0 nltk-3.4.1 numpy-1.18.4 sacremoses-0.0.43 scikit-learn-0.20.3 sentencepiece-0.1.91 spacy-2.3.0 thinc-7.4.1 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESVSUQUwtky7",
        "colab_type": "text"
      },
      "source": [
        "### Workshop Task #1: Create a corpus\n",
        "\n",
        "The first task will be making your own training data based on the above format. We will work a small dataset that we've provided and later some publicly available ones but participants are expected to create their own for this part of the workshop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzUq1qP_tky7",
        "colab_type": "text"
      },
      "source": [
        "## Training Data\n",
        "This is a sample format of the training data we want to use:\n",
        "\n",
        "```\n",
        "training_phrases = {\n",
        "        'when_is_check_in' : ['when is check-in','When can I check in?','when's checkin'],\n",
        "        'where_is_the_front_desk' : ['Where is the front desk?','what is the location of the front desk?'...]}\n",
        "}\n",
        "\n",
        "answers : {\n",
        "        'when_is_check_in' : 'Check in is at 3pm! :)',\n",
        "        'where_is_the_front_desk' : 'The front desk is located on the 2nd floor.'}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYII3CqfvN26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_phrases = {\n",
        "    'too_hot' : ['whew', 'its a bit humid', 'im sweating', 'scarletta', 'i should take this off'],\n",
        "    'too_cold' : ['its chilly', 'do you have a jacket', 'im freezing', 'could you turn the heat on']\n",
        "}\n",
        "\n",
        "answers : {\n",
        "    'too_hot' : 'Turning the temperature down',\n",
        "    'too_cold': 'Turning the temperature up'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWvus6fftky8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REiHK6Yxtky_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "b9ba6a3f-8bfa-47cc-a06f-cd4ec7723e2a"
      },
      "source": [
        "#get training data\n",
        "!wget https://raw.githubusercontent.com/bespoke-inc/bespoke-public-talks/master/2020/2020-08-22-MLT-Rules-to-DL/training_sample.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-22 05:54:19--  https://raw.githubusercontent.com/bespoke-inc/bespoke-public-talks/master/2020/2020-08-22-MLT-Rules-to-DL/training_sample.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16736 (16K) [text/plain]\n",
            "Saving to: ‘training_sample.json’\n",
            "\n",
            "\rtraining_sample.jso   0%[                    ]       0  --.-KB/s               \rtraining_sample.jso 100%[===================>]  16.34K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-08-22 05:54:19 (1.32 MB/s) - ‘training_sample.json’ saved [16736/16736]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6EbGOWktkzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = json.load(open('./training_sample.json','r'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtvBitNetkzF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "58342cf0-2229-40f0-dab3-1b3357ac003c"
      },
      "source": [
        "list(training_data.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hotel.when_is_check_in',\n",
              " 'hotel.when_is_check_out',\n",
              " 'hotel.is_there_early_check_in',\n",
              " 'hotel.is_there_late_check_out',\n",
              " 'hotel.where_is_the_front_desk_located']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRbQ19rKtkzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers = {\n",
        "    'hotel.when_is_check_in': 'Check in is at 3pm!',\n",
        "    'hotel.when_is_check_out': 'Check out is at 10am!',\n",
        "    'hotel.is_there_late_check_out': 'For early check-out or late check-in please schedule beforehand',\n",
        "    'hotel.is_there_early_check_in': 'For early check-out or late check-in please schedule beforehand',\n",
        "    'hotel.where_is_the_front_desk_located': 'Front desk is located on the 2nd floor'\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ca2aAJ2tkzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANRyesJgtkzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punct_re_escape = re.compile('[%s]' % re.escape('!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~'))\n",
        "\n",
        "class MyChatbotData:\n",
        "    \n",
        "    def __init__(self, json_obj, text_fld, answers):\n",
        "        dfs = []\n",
        "        for i, (intent, data) in enumerate(json_obj.items()):\n",
        "            # lowercase and remove punctuation\n",
        "            patterns = data[text_fld].copy()\n",
        "            for i, p in enumerate(patterns):\n",
        "                p = p.lower()\n",
        "                p = self.remove_punctuation(p)\n",
        "                patterns[i] = p\n",
        "                answer = answers[intent]\n",
        "            df = pd.DataFrame(list(zip([intent]*len(patterns), patterns, [answer]*len(patterns))), \\\n",
        "                              columns=['intent', 'phrase', 'answer'])\n",
        "            dfs.append(df)\n",
        "        self.df = pd.concat(dfs)\n",
        "    \n",
        "    def get_answer(self, intent):\n",
        "        return pd.unique(self.df[self.df['intent'] == intent]['answer'])[0]\n",
        "    \n",
        "    def remove_punctuation(self, text):\n",
        "        return punct_re_escape.sub('', text)\n",
        "    \n",
        "    def get_phrases(self, intent):\n",
        "        return list(self.df[self.df['intent'] == intent]['phrase'])\n",
        "    \n",
        "    def get_intents(self):\n",
        "        return list(pd.unique(self.df['intent']))\n",
        "    \n",
        "    def show_batch(self, size=5):\n",
        "        return self.df.head(size)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI_Qxv2FtkzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chatbot_data = MyChatbotData(training_data, 'patterns', answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDOxTp6utkzW",
        "colab_type": "code",
        "colab": {},
        "outputId": "a5d1d0e6-95c8-4433-a8f8-694bc7466984"
      },
      "source": [
        "chatbot_data.show_batch(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intent</th>\n",
              "      <th>phrase</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>when is check-in</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>how to check in</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>what time is the latest we can check into the ...</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>what time is check in open till</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>can you advise the check in time</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>what time is check in for new hotel otani toky...</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>late check in</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>can i check in late</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>what about check in</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>im down to check in</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   intent                                             phrase  \\\n",
              "0  hotel.when_is_check_in                                   when is check-in   \n",
              "1  hotel.when_is_check_in                                    how to check in   \n",
              "2  hotel.when_is_check_in  what time is the latest we can check into the ...   \n",
              "3  hotel.when_is_check_in                    what time is check in open till   \n",
              "4  hotel.when_is_check_in                   can you advise the check in time   \n",
              "5  hotel.when_is_check_in  what time is check in for new hotel otani toky...   \n",
              "6  hotel.when_is_check_in                                      late check in   \n",
              "7  hotel.when_is_check_in                                can i check in late   \n",
              "8  hotel.when_is_check_in                                what about check in   \n",
              "9  hotel.when_is_check_in                                im down to check in   \n",
              "\n",
              "                answer  \n",
              "0  Check in is at 3pm!  \n",
              "1  Check in is at 3pm!  \n",
              "2  Check in is at 3pm!  \n",
              "3  Check in is at 3pm!  \n",
              "4  Check in is at 3pm!  \n",
              "5  Check in is at 3pm!  \n",
              "6  Check in is at 3pm!  \n",
              "7  Check in is at 3pm!  \n",
              "8  Check in is at 3pm!  \n",
              "9  Check in is at 3pm!  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwdaLJdrtkzZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "fbeac22c-a957-44fd-8b0b-9396e7b98b81"
      },
      "source": [
        "len(chatbot_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "368"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ6n3DEAtkzd",
        "colab_type": "text"
      },
      "source": [
        "## Rule-based intent ~~classification~~ matching\n",
        "\n",
        "The simplest approach to find if an query falls into a certain intent is to do some string comparison with our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET_5cIdbtkzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNK = \"I don't know\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtSdMaUBtkzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exact_match(query):\n",
        "    intents = chatbot_data.get_intents()\n",
        "    for i in intents:\n",
        "        phrases = chatbot_data.get_phrases(i)\n",
        "        if query in phrases:\n",
        "            return chatbot_data.get_answer(i)\n",
        "    return UNK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "0VlAst-ztkzj",
        "colab_type": "code",
        "colab": {},
        "outputId": "5d68f9c6-f7fc-4379-e971-21962bbb8dc6"
      },
      "source": [
        "exact_match(\"is there early check-in\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For early check-out or late check-in please schedule beforehand'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OCfDY6WAtkzm",
        "colab_type": "code",
        "colab": {},
        "outputId": "6adab95f-cb13-4c93-c119-1b16159f12f1"
      },
      "source": [
        "exact_match(\"when do i check in\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Check in is at 3pm!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcidR9u6tkzp",
        "colab_type": "code",
        "colab": {},
        "outputId": "e27f34f7-f19c-4d80-a094-e4e3fb9898e0"
      },
      "source": [
        "exact_match(\"can i check-in earlier than 12pm\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't know\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgPOrUJ-tkzs",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "- CJK\n",
        "- normalize contractions\n",
        "- remove hyphens\n",
        "- remove stopwords\n",
        "- check for typos\n",
        "- normalize plurals\n",
        "- normalize ascii\n",
        "- normalize emojis\n",
        "- remove punctuation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiEMB3Rhtkzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "EMOJIS = [[':)', '😀'],[';)', '😉'],[':(', '😞'],[';((', '😢'],[':p', '😛']]\n",
        "_emoji_re = '[\\U00010000-\\U0010ffff]+'\n",
        "emoji_re = re.compile(_emoji_re, flags=re.UNICODE)\n",
        "\n",
        "def emoji_normalize(text):\n",
        "    for e1, e2 in EMOJIS:\n",
        "        text = text.replace(e1, e2)\n",
        "    return text\n",
        "\n",
        "def is_emoji(text):\n",
        "    emoji = \"\".join(re.findall(_emoji_re, text))\n",
        "    return emoji == text\n",
        "\n",
        "def emoji_isolate(text):\n",
        "    EMJ = \"__EMOJI__\"\n",
        "    emoji_list = re.findall(_emoji_re, text)\n",
        "    text = emoji_re.sub(f\" {EMJ} \", text)\n",
        "    new_str, ctr = [], 0\n",
        "    for tok in text.split():\n",
        "        if tok == EMJ:\n",
        "            new_str.append(emoji_list[ctr])\n",
        "            ctr += 1\n",
        "        else:\n",
        "            new_str.append(tok)\n",
        "    return \" \".join(new_str).strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJMeQzLFtkzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unicodedata\n",
        "\n",
        "def ascii_normalize(text):\n",
        "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode(\"utf-8\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7Be85eZtkz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punct_re_escape = re.compile('[%s]' % re.escape('!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~'))\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    punct_re_escape.sub('', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1JwKsu5tkz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    text = ascii_normalize(text) or text\n",
        "    text = emoji_normalize(text) or text\n",
        "    text = emoji_isolate(text) or text\n",
        "    text = remove_punctuation(text) or text\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIU2lq9Htkz5",
        "colab_type": "text"
      },
      "source": [
        "### Workshop Task #2: Further preprocessing steps\n",
        "Add other types of preprocessing relevant to the dataset you created. It could be from any of the ones listed above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inS8RijMtkz6",
        "colab_type": "text"
      },
      "source": [
        "### Partial String Matching\n",
        "Instead of checking is the entire query string exists in our dataset, we try to find a partial match\n",
        "and pick the intent that matches most closely. We will try to do this with using Levenshtein Distance \n",
        "to calculate the differences between sequences. The library [fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy)\n",
        "can help us do this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay5OmVtRtkz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fuzzywuzzy import process"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD5uu4xUtkz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fuzzy_matching(query):\n",
        "    intents = chatbot_data.get_intents()\n",
        "    for i in intents:\n",
        "        phrases = chatbot_data.get_phrases(i)\n",
        "        match, score = process.extractOne(query, phrases)\n",
        "        if score > 90:\n",
        "            return chatbot_data.get_answer(i)\n",
        "    return UNK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr_yoJ-Ltk0B",
        "colab_type": "code",
        "colab": {},
        "outputId": "9ca17d3d-76fe-4903-8396-953da4dac7df"
      },
      "source": [
        "fuzzy_matching(\"when do i check-in\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Check in is at 3pm!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoL2rYxStk0E",
        "colab_type": "code",
        "colab": {},
        "outputId": "f2c81a40-286f-4ae2-92bc-0323db8ac7e6"
      },
      "source": [
        "fuzzy_matching(\"can i check-in earlier than 12pm\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For early check-out or late check-in please schedule beforehand'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28bq3BlVtk0H",
        "colab_type": "code",
        "colab": {},
        "outputId": "0374c5e4-1a71-4294-9f79-a0e7fa9e215b"
      },
      "source": [
        "fuzzy_matching(\"what time is early check-in\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Check in is at 3pm!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmsrFG1Ktk0K",
        "colab_type": "text"
      },
      "source": [
        "## ML Classification\n",
        "We will now add a probabilistic classifier to our set of methods to get better intent classification.\n",
        "The algorithm we will use is [naive bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
        "\n",
        "Naive Bayes classifiers works quite well for small amount of training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUuHOS-Ptk0L",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizer\n",
        "Before we feed it to our model for training we need to tokenize our training instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HAyIryvtk0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okVi44IDtk0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm',parse=False,tagger=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G2wzCqVtk0R",
        "colab_type": "code",
        "colab": {},
        "outputId": "77d87dbf-3425-4284-846e-e003243b7f11"
      },
      "source": [
        "doc = nlp(\"when can i check in?\")\n",
        "[tok.text for tok in doc]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['when', 'can', 'i', 'check', 'in', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxhzz2FHtk0T",
        "colab_type": "code",
        "colab": {},
        "outputId": "383d3d2f-de4b-44fa-8c07-dabaaf8a55f4"
      },
      "source": [
        "doc = nlp(\"when can i check-in?\")\n",
        "[tok.text for tok in doc]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['when', 'can', 'i', 'check', '-', 'in', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrL84bbRtk0W",
        "colab_type": "code",
        "colab": {},
        "outputId": "5a23f15a-6122-4477-cd72-36d59f17b450"
      },
      "source": [
        "doc = nlp(\"i didn't\")\n",
        "[tok.text for tok in doc]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'did', \"n't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-dn8WBJtk0Z",
        "colab_type": "code",
        "colab": {},
        "outputId": "b5276d1b-32d1-452a-e515-24794502a9fd"
      },
      "source": [
        "doc = nlp(\"thank you ありがとう\")\n",
        "[tok.text for tok in doc]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thank', 'you', 'ありがとう']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4_k9TYGtk0b",
        "colab_type": "code",
        "colab": {},
        "outputId": "58c4a109-47c2-4101-f497-6a6089cdee69"
      },
      "source": [
        "doc = nlp(\"didn't    couldn't   \")\n",
        "[tok.text for tok in doc if tok.text.strip()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['did', \"n't\", 'could', \"n't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAiIkX9Ltk0e",
        "colab_type": "code",
        "colab": {},
        "outputId": "ada5f7a0-3ee3-43c7-b5d1-5a453db1cbbd"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/asirsaeed/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_dwtYh0tk0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q1ZDdbqtk0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_nd_join(text):\n",
        "    doc = nlp(text.lower())\n",
        "    return \" \".join(tok.text for tok in doc if tok.text.strip() not in stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wIe1LFRtk0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_xs_ys(train_data):\n",
        "    x, y = [], []\n",
        "    intents = chatbot_data.get_intents()\n",
        "    for i in intents:\n",
        "        phrases = chatbot_data.get_phrases(i)\n",
        "        x += [tokenize_nd_join(phrase) for phrase in phrases]\n",
        "        y += [i]*len(phrases)\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzGLjz4Mtk0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQSjlw0Etk0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(x,y):\n",
        "    vect = CountVectorizer(ngram_range=(1,2),max_features=None)\n",
        "    nb = Pipeline([('vect',vect),('clf',ComplementNB(alpha=1.0,norm=False))])\n",
        "    nb.fit(x,y)\n",
        "    return nb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIbnLTb_tk0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = get_xs_ys(training_data)\n",
        "nb_model = train(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9185chWRtk01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nb_pred(query):\n",
        "    tokenized_query = tokenize_nd_join(query)\n",
        "    pred = nb_model.predict([tokenized_query])[0]\n",
        "    return chatbot_data.get_answer(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlwP5x3Ytk03",
        "colab_type": "code",
        "colab": {},
        "outputId": "9585c4b6-5e3b-4f24-f4d7-37ba33fae7e2"
      },
      "source": [
        "nb_pred(\"what time is early check-in\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For early check-out or late check-in please schedule beforehand'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7d83LR9tk06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BuEeyxLtk09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nb_pred_top3(query):\n",
        "    tokenized_query = tokenize_nd_join(query)\n",
        "    pred_prob = nb_model.predict_proba([tokenized_query])\n",
        "    preds_sorted = np.argsort(pred_prob)\n",
        "    top3 = preds_sorted[:,-1],preds_sorted[:,-2],preds_sorted[:,-2]\n",
        "    if pred_prob[0,top3[0]] > (pred_prob[0,top3[1]] + pred_prob[0,top3[2]]):\n",
        "        pred = nb_model.named_steps['clf'].classes_[top3[0]][0]\n",
        "        return chatbot_data.get_answer(pred)\n",
        "    return UNK\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6uPbalNtk1B",
        "colab_type": "code",
        "colab": {},
        "outputId": "c277765c-4ca5-4e01-fdc1-35a623b782c3"
      },
      "source": [
        "nb_pred_top3(\"is there early check-in\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For early check-out or late check-in please schedule beforehand'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QQ2JT2xtk1E",
        "colab_type": "text"
      },
      "source": [
        "## Intent Classification Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDAIMnN_tk1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pred(query):\n",
        "    query = query.lower()\n",
        "    pred = exact_match(query)\n",
        "    if pred == UNK: pred = exact_match(preprocess(query))\n",
        "    if pred == UNK: pred = nb_pred_top3(query)\n",
        "    if pred == UNK: pred = nb_pred_top3(preprocess(query))\n",
        "    if pred == UNK: pred = fuzzy_matching(query)\n",
        "    if pred == UNK: pred = fuzzy_matching(preprocess(query))\n",
        "    return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHvQcHVltk1I",
        "colab_type": "code",
        "colab": {},
        "outputId": "a4b5c482-6d5d-4f7f-9df3-22ecee9c88da"
      },
      "source": [
        "get_pred(\"when is check-in\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Check in is at 3pm!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37jbO8zktk1K",
        "colab_type": "code",
        "colab": {},
        "outputId": "5af0ed6b-be4d-409d-ed5f-230ac78bb775"
      },
      "source": [
        "get_pred(\"can i check-out late?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For early check-out or late check-in please schedule beforehand'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHFMYfHstk1N",
        "colab_type": "code",
        "colab": {},
        "outputId": "e70df671-f646-46b1-c7f4-fcfbf2cf3623"
      },
      "source": [
        "get_pred(\"where can i find the front desk?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Front desk is located on the 2nd floor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pys-Svx0tk1Q",
        "colab_type": "text"
      },
      "source": [
        "### Moving ML to DL\n",
        "We see that this pipeline using some rules and a probabilistic model are working quite well.\n",
        "However, it doesn't scale with data and requires adding a lot of preprocessing and nuances to get working properly\n",
        "\n",
        "Pros:\n",
        "- There are noticeable improvement in using NNs over the current probabilistic model.\n",
        "- Model can scale with data i.e it can improve as we add more annotated training data\n",
        "- This can be a good point to move to NNs, since we are reaching the limits of rule based systems e.g fewer engineered features\n",
        "- Simplified pipeline\n",
        "\n",
        "Cons:\n",
        "- Huge gains cannot be seen until the data is cleaned. \n",
        "- In its current state, the model will either be the same or slightly better than the current approach.\n",
        "- Infrastructure changes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdkKXcKDtk1R",
        "colab_type": "text"
      },
      "source": [
        "## Classification with Distil Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ5SdkjBtk1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.text import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7qq58NBtk1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers = {\n",
        "    'hotel.when_is_check_in': 'Check in is at 3pm!',\n",
        "    'hotel.when_is_check_out': 'Check out is at 10am!',\n",
        "    'hotel.is_there_late_check_out': 'For early check-out or late check-in please schedule beforehand',\n",
        "    'hotel.is_there_early_check_in': 'For early check-out or late check-in please schedule beforehand',\n",
        "    'hotel.where_is_the_front_desk_located': 'Front desk is located on the 2nd floor'\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-AsDDB7tk1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyChatbotData:\n",
        "    \n",
        "    def __init__(self, json_obj, text_fld, answers):\n",
        "        dfs = []\n",
        "        for i, (intent, data) in enumerate(json_obj.items()):\n",
        "            # lowercase and remove punctuation\n",
        "            patterns = data[text_fld].copy()\n",
        "            for i, p in enumerate(patterns):\n",
        "                p = p.lower()\n",
        "                p = self.remove_punctuation(p)\n",
        "                patterns[i] = p\n",
        "                answer = answers[intent]\n",
        "            df = pd.DataFrame(list(zip([intent]*len(patterns), patterns, [answer]*len(patterns))), \\\n",
        "                              columns=['intent', 'phrase', 'answer'])\n",
        "            dfs.append(df)\n",
        "        self.df = pd.concat(dfs)\n",
        "    \n",
        "    def get_answer(self, intent):\n",
        "        return pd.unique(self.df[self.df['intent'] == intent]['answer'])[0]\n",
        "    \n",
        "    def remove_punctuation(self, text):\n",
        "        return punct_re_escape.sub('', text)\n",
        "    \n",
        "    def get_phrases(self, intent):\n",
        "        return list(self.df[self.df['intent'] == intent]['phrase'])\n",
        "    \n",
        "    def get_intents(self):\n",
        "        return list(pd.unique(self.df['intent']))\n",
        "    \n",
        "    def show_batch(self, size=5):\n",
        "        return self.df.head(size)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5OspOestk1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = json.load(open('./training_sample.json','r'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QIV8trctk1d",
        "colab_type": "code",
        "colab": {},
        "outputId": "24421d8a-47f0-4100-e16f-a6d98aab8bbe"
      },
      "source": [
        "list(training_data.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hotel.when_is_check_in',\n",
              " 'hotel.when_is_check_out',\n",
              " 'hotel.is_there_early_check_in',\n",
              " 'hotel.is_there_late_check_out',\n",
              " 'hotel.where_is_the_front_desk_located']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS78ZUpTtk1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chatbot_data = MyChatbotData(training_data, 'patterns', answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJDx9rLGtk1k",
        "colab_type": "code",
        "colab": {},
        "outputId": "2f9ea132-196e-434d-a53d-c4db3b29f888"
      },
      "source": [
        "df = chatbot_data.df\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intent</th>\n",
              "      <th>phrase</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>when is check-in</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>how to check in</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>what time is the latest we can check into the ...</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>what time is check in open till</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hotel.when_is_check_in</td>\n",
              "      <td>can you advise the check in time</td>\n",
              "      <td>Check in is at 3pm!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   intent                                             phrase  \\\n",
              "0  hotel.when_is_check_in                                   when is check-in   \n",
              "1  hotel.when_is_check_in                                    how to check in   \n",
              "2  hotel.when_is_check_in  what time is the latest we can check into the ...   \n",
              "3  hotel.when_is_check_in                    what time is check in open till   \n",
              "4  hotel.when_is_check_in                   can you advise the check in time   \n",
              "\n",
              "                answer  \n",
              "0  Check in is at 3pm!  \n",
              "1  Check in is at 3pm!  \n",
              "2  Check in is at 3pm!  \n",
              "3  Check in is at 3pm!  \n",
              "4  Check in is at 3pm!  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zt9XFk3tk1m",
        "colab_type": "text"
      },
      "source": [
        "Since the sample dataset may be bit too small for this part of the workshop we will be using a public one\n",
        "from [here](https://www.kaggle.com/hassanamin/atis-airlinetravelinformationsystem/data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIPNt_Hwtk1n",
        "colab_type": "code",
        "colab": {},
        "outputId": "0aa2b5f0-e677-4f5c-fbff-a2b4f78b4c68"
      },
      "source": [
        "df = pd.read_csv(\"284285_585165_bundle_archive/atis_intents.csv\",header=0,names=['intent', 'phrase'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intent</th>\n",
              "      <th>phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>what flights are available from pittsburgh to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>atis_flight_time</td>\n",
              "      <td>what is the arrival time in san francisco for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>cheapest airfare from tacoma to orlando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>round trip fares from pittsburgh to philadelp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>i need a flight tomorrow from columbus to min...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             intent                                             phrase\n",
              "0       atis_flight   what flights are available from pittsburgh to...\n",
              "1  atis_flight_time   what is the arrival time in san francisco for...\n",
              "2      atis_airfare            cheapest airfare from tacoma to orlando\n",
              "3      atis_airfare   round trip fares from pittsburgh to philadelp...\n",
              "4       atis_flight   i need a flight tomorrow from columbus to min..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzUcurUBtk1p",
        "colab_type": "code",
        "colab": {},
        "outputId": "bfcdd16d-5b0f-47f6-f11e-81886173323b"
      },
      "source": [
        "len(set(df['intent'])), len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22, 4977)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG_oJO_Ntk1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = Path('./')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJHrMNoctk1u",
        "colab_type": "text"
      },
      "source": [
        "Adapting fastai code for training transformers was inspired from this [blog post](https://towardsdatascience.com/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S28VE7x_tk1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
        "from transformers import PreTrainedTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1i-P417tk1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        tokens = [CLS] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [SEP]\n",
        "        return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HqhT5aVtk1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1mg3uT-tk10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
        "        \n",
        "    def __getstate__(self):\n",
        "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
        "\n",
        "    def __setstate__(self, state:dict):\n",
        "        self.itos = state['itos']\n",
        "        self.tokenizer = state['tokenizer']\n",
        "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SibATWKEtk12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
        "\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, \n",
        "                                       include_bos=False, \n",
        "                                       include_eos=False)\n",
        "\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umaG0HFbtk14",
        "colab_type": "code",
        "colab": {},
        "outputId": "fc9befaf-0c6b-4da2-a646-89b43867ea43"
      },
      "source": [
        "pad_idx = transformer_tokenizer.pad_token_id\n",
        "\n",
        "databunch = (TextList.from_df(df, cols='phrase', processor=transformer_processor)\n",
        "             .split_by_rand_pct()\n",
        "             .label_from_df(cols= 'intent')\n",
        "             .databunch(bs=64, pad_first=False, pad_idx=pad_idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtVMR3dMtk16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformerModel(nn.Module):\n",
        "  \n",
        "    def __init__(self, transformer):\n",
        "        super(TransformerModel,self).__init__()\n",
        "        self.transformer = transformer\n",
        "        \n",
        "    def forward(self, input_ids):\n",
        "        # Return only the logits from the transfomer\n",
        "        logits = self.transformer(input_ids)[0]   \n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaXa8Nuhtk18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = DistilBertConfig.from_pretrained('distilbert-base-uncased')\n",
        "config.num_labels = databunch.train_ds.c\n",
        "\n",
        "distil_bert = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)\n",
        "transformer_model = TransformerModel(distil_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upHoVWtqtk19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AdamW\n",
        "from functools import partial\n",
        "\n",
        "CustomAdamW = partial(AdamW, correct_bias=False)\n",
        "\n",
        "learn = Learner(databunch, transformer_model, opt_func = CustomAdamW, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSpkv9Kdtk1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "list_layers = [learn.model.transformer.base_model.embeddings,\n",
        "               learn.model.transformer.base_model.transformer.layer[0],\n",
        "               learn.model.transformer.base_model.transformer.layer[1],\n",
        "               learn.model.transformer.base_model.transformer.layer[2],\n",
        "               learn.model.transformer.base_model.transformer.layer[3],\n",
        "               learn.model.transformer.base_model.transformer.layer[4],\n",
        "               learn.model.transformer.base_model.transformer.layer[5],\n",
        "               learn.model.transformer.pre_classifier,\n",
        "               learn.model.transformer.classifier]\n",
        "               \n",
        "learn.split(list_layers);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klwEvKE6tk2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.freeze_to(-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "h84WEig9tk2E",
        "colab_type": "code",
        "colab": {},
        "outputId": "63819495-4415-4657-bead-06613135cdf0"
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot(skip_end=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      50.00% [1/2 02:18<02:18]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.009273</td>\n",
              "      <td>#na#</td>\n",
              "      <td>02:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='17' class='' max='62', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      27.42% [17/62 01:56<05:07 6.1479]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC3RqU5Dtk2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(3,max_lr=1e-3,moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAVILms8tk2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(2, slice(8e-4/(2.6**4),8e-4), moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z2aHbuqtk2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.freeze_to(-5)\n",
        "learn.fit_one_cycle(2, slice(5e-4/(2.6**4),5e-4), moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TztKfBpdtk2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.freeze_to(-8)\n",
        "learn.fit_one_cycle(2, slice(3e-4/(2.6**4),3e-4), moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ-WCkUJtk2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(5, slice(1e-4/(2.6**4),1e-4), moms=(0.8,0.7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9j43kA7tk2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.predict(\"what flights are available from pittsburgh to baltimore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHaZvApktk2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interp = TextClassificationInterpretation(learn,*learn.get_preds(with_loss=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8chguUUtk2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interp.show_top_losses(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttIdPjkUtk2W",
        "colab_type": "text"
      },
      "source": [
        "### Workshop Task 3: Using Named Entity Recognition to extract parameters (10 min)\n",
        "Generalizing your training data with entity classes\n",
        "Add named entities to one intent and use spaCy to extract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDMuLNmjtk2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ParameterModel():\n",
        "    \n",
        "    def __init__(self, param_list):\n",
        "        self.parameters = param_list\n",
        "        self.label_ = 'PARAM'\n",
        "    \n",
        "    def replace_entities(self, text):\n",
        "        \"\"\"Replace entities in the text with their respective labels\"\"\"\n",
        "        entity_replaced_text = text\n",
        "        for p in self.parameters:\n",
        "            if p in text:\n",
        "                entity_replaced_text = text.replace(p, f'<__{self.label_}__>')\n",
        "        return entity_replaced_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvsKXH-ltk2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "food_list = ['japanese','indian','thai','chinese','fast food','bbq','cafe']\n",
        "food_param_model = ParameterModel(food_list) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1uZmzTBtk2b",
        "colab_type": "code",
        "colab": {},
        "outputId": "7d24f1a7-98f4-4a6e-ba4e-a1fe58d1802c"
      },
      "source": [
        "food_param_model.replace_entities(\"I want fast food\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I want <__PARAM__>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aIIpH8Ytk2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_NAME = 'en_core_web_md'\n",
        "\n",
        "class SpacyModel(object):\n",
        "    spacy_model = None  # Where we keep the model when it's loaded\n",
        "\n",
        "    @classmethod\n",
        "    def get_base_spacy_model(cls):\n",
        "        \"\"\"Get the base spacy model\"\"\"\n",
        "        if not cls.spacy_model:\n",
        "            cls.spacy_model = spacy.load(MODEL_NAME)\n",
        "        return cls.spacy_model\n",
        "    \n",
        "    @classmethod\n",
        "    def replace_entities(cls, text):\n",
        "        \"\"\"Replace entities in the text with their respective labels\"\"\"\n",
        "        spacy_model = cls.get_base_spacy_model()\n",
        "        doc = spacy_model(text)\n",
        "        entity_replaced_text = text\n",
        "        for e in reversed(doc.ents):\n",
        "            start = e.start_char\n",
        "            end = start + len(e.text)\n",
        "            entity_replaced_text = entity_replaced_text[:start] + f'<__{e.label_}__>' + entity_replaced_text[end:]\n",
        "        return entity_replaced_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-SLKuqotk2f",
        "colab_type": "code",
        "colab": {},
        "outputId": "d69a2614-8303-4503-c140-0fcd7e8f8556"
      },
      "source": [
        "SpacyModel.replace_entities(\"how do i get to shibuya\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'how do i get to <__GPE__>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfHe41jZtk2h",
        "colab_type": "code",
        "colab": {},
        "outputId": "b9068529-09f8-4da1-ce74-fe4d54743152"
      },
      "source": [
        "SpacyModel.replace_entities(\"can i get a reservation for Sunday\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'can i get a reservation for <__DATE__>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nD5n2Tetk2i",
        "colab_type": "text"
      },
      "source": [
        "### Workshop Task 4: Using users to disambiguate intents (10 min)\n",
        "When two intents are good candidates for the user's text, instead of picking the best, ask the user which they meant.\n",
        "Add disambiguation ability in your bot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbpSE_Ggtk2j",
        "colab_type": "text"
      },
      "source": [
        "### Workshop Task 5: Typos (10 min)\n",
        "Since users are typing in their text, errors are common. Hence, the bot must be resilient to typos\n",
        "Add typo correction in your bot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzdcnpIgtk2j",
        "colab_type": "text"
      },
      "source": [
        "## Putting it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSs3c64Xtk2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_entities(text):\n",
        "    entity_replaced = SpacyModel.replace_entities(text)\n",
        "    entity_replaced = food_param_model.replace_entities(entity_replaced)\n",
        "    return entity_replaced"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acEzoQK2tk2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextFactory:\n",
        "\n",
        "    def __init__(self, text):\n",
        "        self.raw = text\n",
        "        self._sanitized = None\n",
        "        self._entity_replaced = None\n",
        "        self._sanitized_and_entity_replaced = None\n",
        "\n",
        "    def sanitized(self):\n",
        "        if not self._sanitized:\n",
        "            self._sanitized = preprocess(self.raw)\n",
        "        return self._sanitized\n",
        "    \n",
        "    def entity_replaced(self):\n",
        "        if not self._entity_replaced:\n",
        "            self._entity_replaced = replace_entities(self.raw)\n",
        "        return self._entity_replaced\n",
        "\n",
        "    def typo_corrected(self):\n",
        "        #if not self._typo_corrected:\n",
        "        #    self._typo_corrected = typo_correct(self.raw)\n",
        "        #return self._typo_corrected\n",
        "        pass\n",
        "\n",
        "    def sanitized_and_entity_replaced(self):\n",
        "        if not self._sanitized_and_entity_replaced:\n",
        "            self._sanitized_and_entity_replaced = replace_entities(self.sanitized())\n",
        "        return self._sanitized_and_typo_corrected"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_b9nXJltk2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClassifierBuilder:\n",
        "\n",
        "    def __init__(self, query):\n",
        "        self.raw_query = query\n",
        "        self.queries = []\n",
        "        self.classifiers = []\n",
        "    \n",
        "    def add_classifiers_query(self, classifier, query):\n",
        "        self.classifiers.append(classifier)\n",
        "        self.queries.append(query)\n",
        "        return self\n",
        "    \n",
        "    def build(self):\n",
        "        # validation\n",
        "        if not self.classifiers:\n",
        "            raise Exception('Must specify classifiers')\n",
        "        # build\n",
        "        preds = None\n",
        "        for c in self.classifiers:\n",
        "            pred = c.predict(self.raw_query)\n",
        "            if pred != UNK:\n",
        "                return pred\n",
        "        return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrtBNNwGtk2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyChatbotData:\n",
        "    \n",
        "    def __init__(self, json_obj, text_fld, answers):\n",
        "        dfs = []\n",
        "        for i, (intent, data) in enumerate(json_obj.items()):\n",
        "            # lowercase and remove punctuation\n",
        "            patterns = data[text_fld].copy()\n",
        "            for i, p in enumerate(patterns):\n",
        "                p = p.lower()\n",
        "                patterns[i] = p\n",
        "                answer = answers[intent]\n",
        "            df = pd.DataFrame(list(zip([intent]*len(patterns), patterns, [answer]*len(patterns))), \\\n",
        "                              columns=['intent', 'phrase', 'answer'])\n",
        "            dfs.append(df)\n",
        "        self.df = pd.concat(dfs)\n",
        "    \n",
        "    def get_answer(self, intent):\n",
        "        return pd.unique(self.df[self.df['intent'] == intent]['answer'])[0]\n",
        "    \n",
        "    def remove_punctuation(self, text):\n",
        "        return punct_re_escape.sub('', text)\n",
        "    \n",
        "    def get_phrases(self, intent):\n",
        "        return list(self.df[self.df['intent'] == intent]['phrase'])\n",
        "    \n",
        "    def get_intents(self):\n",
        "        return list(pd.unique(self.df['intent']))\n",
        "    \n",
        "    def show_batch(self, size=5):\n",
        "        return self.df.head(size)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7i2TL3Btk2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ExactMatch:\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def predict(self, query):\n",
        "        intents = self.data.get_intents()\n",
        "        for i in intents:\n",
        "            phrases = self.data.get_phrases(i)\n",
        "            if query in phrases:\n",
        "                return i\n",
        "        return UNK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRtfOUyhtk2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FuzzyMatch:\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "    \n",
        "    def predict(self, query):\n",
        "        intents = self.data.get_intents()\n",
        "        for i in intents:\n",
        "            phrases = self.data.get_phrases(i)\n",
        "            match, score = process.extractOne(query, phrases)\n",
        "            if score > 90:\n",
        "                return chatbot_data.get_answer(i)\n",
        "        return UNK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdazJST-tk2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NaiveBayesMatch:\n",
        "    \n",
        "    def __init__(self, data, model):\n",
        "        self.data = data\n",
        "        self.nb_model = model\n",
        "        \n",
        "    def predict(self, query):\n",
        "        tokenized_query = tokenize_nd_join(query)\n",
        "        pred_prob = nb_model.predict_proba([tokenized_query])\n",
        "        preds_sorted = np.argsort(pred_prob)\n",
        "        top3 = preds_sorted[:,-1],preds_sorted[:,-2],preds_sorted[:,-2]\n",
        "        if pred_prob[0,top3[0]] > (pred_prob[0,top3[1]] + pred_prob[0,top3[2]]):\n",
        "            pred = nb_model.named_steps['clf'].classes_[top3[0]][0]\n",
        "        return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaUalbk9tk2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DistilBertMatch:\n",
        "    def __init__(self, data, learner):\n",
        "        self.data = data\n",
        "        self.learner = learner\n",
        "    \n",
        "    def predict(self, query):\n",
        "        pred, idx, probs = self.learner.predict(query)\n",
        "        return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdPXTELAtk2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exact_match_classifier = ExactMatch(chatbot_data)\n",
        "fuzzy_match_classifier = FuzzyMatch(chatbot_data)\n",
        "naive_bayes_classifier = NaiveBayesMatch(chatbot_data, nb_model)\n",
        "distil_bert_classifier = DistilBertMatch(chatbot_data, learn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNTrcWVDtk2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Predictor:\n",
        "    def __init__(self, query):\n",
        "        self.text_factory = TextFactory(query)\n",
        "        self.pipeline = ClassifierBuilder(query)\n",
        "\n",
        "    def predict(self):\n",
        "        pred = self.pipeline.add_classifiers_query(exact_match_classifier, self.text_factory.raw) \\\n",
        "                            .add_classifiers_query(exact_match_classifier, self.text_factory.sanitized()) \\\n",
        "                            .add_classifiers_query(exact_match_classifier, self.text_factory.entity_replaced()) \\\n",
        "                            .add_classifiers_query(distil_bert_classifier, self.text_factory.raw) \\\n",
        "                            .add_classifiers_query(distil_bert_classifier, self.text_factory.sanitized()) \\\n",
        "                            .add_classifiers_query(distil_bert_classifier, self.text_factory.entity_replaced()) \\\n",
        "                            .add_classifiers_query(fuzzy_match_classifier, self.text_factory.raw) \\\n",
        "                            .build()\n",
        "        return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5qoLEvDtk21",
        "colab_type": "code",
        "colab": {},
        "outputId": "f85ac28b-2f72-4070-f957-23d79cdeb1b5"
      },
      "source": [
        "predictor = Predictor(\"what time is check-in\")\n",
        "predictor.predict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hotel.when_is_check_in'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LixXMCstk23",
        "colab_type": "text"
      },
      "source": [
        "### Workshop Task 5: Put together a pipeline for your bot (10 min)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7h5I_kItk23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}